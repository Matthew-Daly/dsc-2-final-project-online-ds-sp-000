{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "* Student name: Pedro Jofre Lora\n",
    "* Student pace: self paced\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Eli Thomas\n",
    "* Blog post URL: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Deliverables\n",
    "The goal of your project is to query the database to get the data needed to perform a statistical analysis. In this statistical analysis, you'll need to perform a hypothesis test (or perhaps several) to answer the following question:\n",
    "\n",
    "Do discounts have a statistically significant effect on the number of products customers order? If so, at what level(s) of discount?\n",
    "\n",
    "In addition to answering this question with a hypothesis test, you will also need to come up with at least 3 other hypotheses to test on your own. These can by anything that you think could be imporant information for the company.\n",
    "\n",
    "For this hypothesis, be sure to specify both the null hypothesis and the alternative hypothesis for your question. You should also specify if this is one-tail or a two-tail test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making recommendations to the Northwind Trading Company to improve performance based on hypothesis testing using frequentist and bayesian methods. \n",
    "### Table of Contents\n",
    "1. [Introduction](#1) <br>\n",
    "2. [Previewing Data](#2) <br>\n",
    "3. [Forming Questions for Analysis](#3) <br>\n",
    "4. [A Reminder on Hypothesis Statements](#4) <br>\n",
    "5. [Do Discounts Increase Order Volume](#5) <br>\n",
    "6. [Do Discounts Increase the Gross Profit of an Order?](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Previewing Data\n",
    "Given that Northwind Trading Company is a fictitious entity, I need to look at the example data that is stored in the database in order to orient myself and begin to ask meaningful questions. I will look at the first 10 or so entries of every table in the database without being selective of the data. The function will also let me look at some of the metadata and the properties of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from ipywidgets import interact, interactive\n",
    "# I'll learn to use plotly in this project since there's a lot of talk about how much more powerful it is than matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a connection to the sql server. I'll use sqlite3 for now, but I may switch to another sql module later if I need it.\n",
    "connect = sql.connect('Northwind_small.sqlite')\n",
    "c = connect.cursor()\n",
    "# Get table names\n",
    "raw = c.execute(\"\"\"select name from sqlite_master where type = 'table'\"\"\").fetchall()\n",
    "tables = []\n",
    "for table in raw:\n",
    "    tables.append(table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d83d68915b407885e0cd0db252c8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Table', options=('Employee', 'Category', 'Customer', 'Shipper', 'S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def table_preview(Table = tables, Preview = ['Head','Description', 'Shape','Unique','Types']):\n",
    "    statement = \"SELECT * FROM [\" + Table + \"]\"\n",
    "    df = pd.read_sql_query(statement, connect)\n",
    "    preview_return = {'Head':df.head(10), 'Description':df.describe(), \n",
    "                      'Shape':df.shape, 'Unique':df.nunique(axis = 0), 'Types':df.dtypes}\n",
    "    out = preview_return[Preview]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an overview of the available, pertinent data:\n",
    "*  **Employees**\n",
    "    - There are 9 employees. 5 are in the USA, and 4 are in the UK\n",
    "    - The notes include information about education\n",
    "    - The hire date is likely incorrect, since the data is in the future (2024) and the order dates are in 2012.\n",
    "*  **Categories**\n",
    "    - Northwind Trading Company trades in food products\n",
    "    - There are 8 categories of food products\n",
    "*  **Customers**\n",
    "    - There are 91 customers\n",
    "    - Contact Title may be interesting to explore (e.g. President, Sales Rep). There are 12 unique values\n",
    "    - Region and Country may also be interesting to explore. There are 9 regions and 21 countries\n",
    "*  **Shipper**\n",
    "    - There are three shippers\n",
    "*  **Suppliers**\n",
    "    - There are 29 suppliers\n",
    "    - The suppliers are scattered globally in 11 distinct regions\n",
    "*  **Orders**\n",
    "    - There are 830 orders\n",
    "    - Only 89 customers have made purchases\n",
    "    - There are only 387 confirmed ship dates. This is concerning...\n",
    "*  **Products**\n",
    "    - There are 77 unique products, 2 of which are discontinued\n",
    "    - 62 products have unit prices\n",
    "*  **Order Details**\n",
    "    - There are a total of 2155 unique product orders. These represent the products that were ordered in the 830 customer orders.\n",
    "    - The discount information resides in the Order Details\n",
    "    - There are more Unit Prices than unique products, which is a signal that either 1) customers receive different unit prices, or 2) Unit Prices include the applied discount\n",
    "*  **Territories and Regions**\n",
    "    - There are 4 nondescript territories, and 52 unique regions.\n",
    "    - Only 49 territories are assigned to employees\n",
    "*  **There Are No Customer Demographic Data**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Forming Questions for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we're consultants tasked with improving the performance of the Northwind Trading Company by giving broad recommendations about new procedures to implement. These procedures could involve anything from the rate and frequency of discounts, to the distribution of employees to customers. In order to give recommendations, we should look to determine what differences, if any, exist between a set of conditions. We can, and should, try to control for other factors whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is helpful to identify the metrics by which to measure success in order to narrow the field of questions that can be asked. The important metrics of success, or performance, are the following listed from most to least important:\n",
    "1. Gross Profit (Greater is better)\n",
    "2. Gross Profit Margin (Greater is better)\n",
    "3. Order Regularity as measured by variability (Lesser is better)\n",
    "4. Order Volume (Greater is better)\n",
    "5. Customer Satisfaction as measured by a synthetic analog (e.g. shipping times) (Greater is Better)\n",
    "6. Employee Productivity as measured by a synthetic analog (e.g. profit normalized by number of assigned customers) (Greater is Better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must assume that the order of importance listed above aligns with the Northwind Trading Company. In reality, the metrics of success would likely be codeveloped between the client and the consultant to ensure that the expectations about the results are congruent between both parties. The consultant brings information into the equation that the client may be blind to (e.g. knowledge from other industries, best practices, etc), just as the client brings information into the equation that the consultant simply cannot know (e.g. the values of the business, the vision, etc). The above list represents a likely way that a corporate entity would prioritize success.\n",
    "\n",
    "Having defined the metrics that can be measured, it is now possible to begin to ask questions that will likely modify those metrics. Some questions are listed below in association with their metric. This is not an exhaustive list, and again some of these questions would be coconstructed with the client:\n",
    "\n",
    "1. Gross Profit\n",
    "    - Do discounts improve the profit of an order? \n",
    "    - Does any one category produce more profit than every other on a per order basis? \n",
    "    - Does any one employee produce more profit than every other on a per order basis?\n",
    "    - Are there month(s) of the year that produce more profit?\n",
    "    - Does a customer with a higher corporate rank (e.g. President vs Associate) produce more profit?\n",
    "2. Gross Profit Margin\n",
    "    - Does any one category produce a higher profit margin than every other after accounting for order quantities?\n",
    "    - Does any one supplier have a higher profit margin than every other supplier?\n",
    "3. Order Regularity\n",
    "    - Does any one employee have more order regularity than every other employee?\n",
    "    - Is any one product category more regular than every other?\n",
    "    - Does any one region order with more regularity than every other region?\n",
    "4. Order Volume\n",
    "    - Do discounts increase order volume?\n",
    "        - Are discounts more successful in certain regions at increasing order volume?\n",
    "    - Does any one customer have a higher order volume more than every other?\n",
    "    - Is any one supplier's foods favored?\n",
    "5. Customer Satisfaction\n",
    "    - Does customer satisfaction impact gross profits?\n",
    "6. Employee Productivity\n",
    "    - Does any one employee produce more orders after normalizing for their number of customers?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the above questions can be followed up by asking, \"if so, to what extent is there a difference?\" It is important to determine that there is, in fact, a statistical difference in the first place before jumping to conclusions, which is why each question is asked as a binary event.\n",
    "\n",
    "For the sake of this notebook, I will attend to four of the above questions to show the kind of work that is necessary in order to perform the full analysis. Two of the questions will be answered using a frequentist approach (e.g. two-sample t-test of means), while the other two questions will be answered using a bayesian approach. Each question will be answered in its own section (Sections 5-8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. A Reminder on Hypothesis Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical significance requires that a null hypothesis, H$_0$, be evaluated in the context of an alternative hypothesis, H$_a$, and a prescribed tolerance for rejecting the null hypothesis, $\\alpha$. It is customary to set $\\alpha$ at 0.05, which indicates that we must have \"95% confidence\" in rejecting our assumptions. The $\\alpha$ value represents more than our confidence; it represents the likelihood of Type I error (and by extension the Type II error), the probability of producing the current findings in a prescribed probability distribution, and a measure of the difference between samples (or groups of samples) given a standard deviation. An $\\alpha$ value of 0.05 balances Type I and Type II errors, and represents almost 4 standard deviations to the left and right of the expected value as prescribed in the null hypothesis. $\\alpha$ = 0.05 will be used for the entirety of this anaylsis.\n",
    "\n",
    "One final note about hypothesis statements: In any statistical test, *the goal is to reject the null hypothesis* in order to demonstrate that there is little evidence to believe that a certain relationship exists between two samples. The null hypothesis is thus the relationship that we want to claim is **False** between our two samples. Rejecting the null hypothesis does not mean that we accept the alternative hypothesis. It simply means that we reject the null hypothesis and offer the alternative hypothesis as a reasonable alternative. It is often the goal to make the alternative hypothesis the *only possible alternative hypothesis*, in which case we must accept the alternative hypothesis if we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. Do discounts increase order volume?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Hypothesis statement\n",
    "I am interested in determining if discounts have an impact on the volume of a product that is ordered. Intuition tells me that discounts modify behavior, so I expect that there will be a difference. As such, I am comparing if the *average volume sold of a product, or in a transaction, is equal to or less in the context of a discount*. The null hypothesis, the hypothesis that I hope to reject, is that there is at most no difference in order volume despite discounts. The alternative hypothesis is that there is a difference.\n",
    "\n",
    "<center> H$_0$: $\\mu_{O|D}$ ≤ $\\mu_{O|ND}$ </center>\n",
    "<center>H$_a$: $\\mu_{O|D}$ > $\\mu_{O|ND}$</center>\n",
    "Where:<br>\n",
    "$\\mu_{O|ND}$ $\\equiv$ The average number of products a customer orders in a transaction given that there are no discounts.<br>\n",
    "$\\mu_{O|D}$ $\\equiv$ The average number of products a customer orders in a transaction given that there are discounts.<br><br>\n",
    "This is a one-tailed test, since I am only interested in determining if discounts increase the order volume. I could ask instead if there is a difference, but I'll cut straight to the chase for this analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will check two scenarios. One in which the volume of a *specific product* is different in the context of a discount, and another in which the volume of a *specific order* is different inn the context of any discounted item in that order. Both of these are described well by the null and alternative hypotheses without their modification, though if it is necessary to be rigorous than the definitions could be explained as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain data to assess whether products are ordered in higher volumes if discounted\n",
    "d_product_statement = \"\"\"SELECT ProductId, Quantity, Discount\n",
    "                         FROM OrderDetail\n",
    "                         WHERE Discount > 0\"\"\"\n",
    "nd_product_statement = \"\"\"SElECT ProductId, Quantity, Discount\n",
    "                          FROM OrderDetail\n",
    "                          WHERE Discount == 0\"\"\"\n",
    "d_product = pd.read_sql_query(d_product_statement,connect)\n",
    "nd_product = pd.read_sql_query(nd_product_statement,connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain data to assess whether orders have higher volume if a product is discounted\n",
    "# Note that these SQL queries are nested. The primary SQL query requests data from the nested SQL query based on a condition of a value in the nested query. This allows me to return the min and max discounts in an order while aggregating the order quantity correctly.\n",
    "d_order_statement = \"\"\"SELECT OrderId, \n",
    "                              Quantity, \n",
    "                              MaxDiscount, \n",
    "                              MinDiscount\n",
    "                       FROM (\n",
    "                            SELECT OrderId,\n",
    "                                   SUM(Quantity) as Quantity,\n",
    "                                   MAX(Discount) AS MaxDiscount,\n",
    "                                   MIN(Discount) AS MinDiscount\n",
    "                            FROM OrderDetail\n",
    "                            GROUP BY OrderId\n",
    "                            )\n",
    "                       WHERE MaxDiscount > 0\n",
    "                       GROUP BY OrderId\"\"\"\n",
    "\n",
    "nd_order_statement =\"\"\"SELECT OrderId, \n",
    "                              Quantity, \n",
    "                              MaxDiscount, \n",
    "                              MinDiscount\n",
    "                       FROM (\n",
    "                            SELECT OrderId,\n",
    "                                   SUM(Quantity) as Quantity,\n",
    "                                   MAX(Discount) AS MaxDiscount,\n",
    "                                   MIN(Discount) AS MinDiscount\n",
    "                            FROM OrderDetail\n",
    "                            GROUP BY OrderId\n",
    "                            )\n",
    "                       WHERE MaxDiscount == 0\n",
    "                       GROUP BY OrderId\"\"\"\n",
    "statements = [d_order_statement,nd_order_statement]\n",
    "df = []\n",
    "for statement in statements:\n",
    "    raw = c.execute(statement)\n",
    "    data = raw.fetchall()\n",
    "    columns = raw.description\n",
    "    temp = pd.DataFrame(data)\n",
    "    temp.columns = [column[0] for column in columns]\n",
    "    df.append(temp)\n",
    "\n",
    "d_order = df[0]\n",
    "nd_order = df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Do discounts increase the order volume of a specific product?\n",
    "In order to test this hypothesis, I'll perform a one-way repeated-measures (within group) t-test. This test checks to see if the order quantity is greater for each specific product when there is a discount. Since each product is likely ordered at a different rate, I cannot simply compare the means of the whole population. This test is equivalent to asking if a certain drug helps lower blood pressure in a group of people. They may not all have the same blood pressure to start, so the test asks if the group experienced a decrease from their *individual baseline* blood pressure, instead of asking if the group as a whole had a lower blood pressure at the end.<br>\n",
    "The one-way repeated measures t-test is equivalent to the one-sample t-test, but it uses the differences within samples before and after treatment as the sample. Said plainly,  I'm looking to see if the difference is statistically significantly greater than 0. Unfortunately, repeated measures require that the datasets be balanced in a 1:1 ratio, so I'll use the mean volume of orders for each product as the measure to ensure this requirement is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=4.353556212659166, pvalue=4.125479020162525e-05)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import statistical package for Repeated Measured Anova\n",
    "from scipy.stats import ttest_1samp\n",
    "# Obtain difference in mean between the same products\n",
    "d_product_mean = d_product.groupby('ProductId').Quantity.mean()\n",
    "nd_product_mean = nd_product.groupby('ProductId').Quantity.mean()\n",
    "d_nd_diff = d_product_mean-nd_product_mean\n",
    "# Run One-way Anova\n",
    "results = ttest_1samp(d_nd_diff,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ttest_1samp calculates a two-tailed t-test, I must interpret the results. The one-tailed t-test results can be inferred from the two-tailed results: the level of significance that must be met is p < 2•$\\alpha$, and t > 0. In this case, both are true, so we reject the null hypothesis that discounts produce fewer or equal number of orders, and accept the alternative hypothesis that **discounts increase the number of orders for a given product**.<br>\n",
    "The effect size is computed using Cohen's d estimate as prescribed in the original publication:<br><br>\n",
    "<center>d = $\\frac{\\mu_1-\\mu_2}{s}$ </center>\n",
    "<br>\n",
    "<center>s = $\\sqrt{\\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}$ </center>\n",
    "<br>\n",
    "This is done 'by hand' below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d = 0.493\n"
     ]
    }
   ],
   "source": [
    "s = np.sqrt(((len(d_nd_diff)-1)*d_nd_diff.std()**2+0)/(len(d_nd_diff)-2))\n",
    "d = (d_nd_diff.mean()-0)/s\n",
    "print(\"Cohen's d = {0:1.3f}\".format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Cohen, this is a medium effect size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Do discounts increase the order volume of individual orders?\n",
    "This analysis is simpler since I'm comparing the average total volume of an order with and without discounts. I can't control for which items make it into the basket because the number of possible combinations would likely leave me with one sample in each unique order composition. I'll simply look at whether or not orders that contain at least one item with a discount have greater volume than those that don't. This is a two-sample, one-tailed t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 2.394e-09\n",
      "t statistic = 5.917\n",
      "Cohen's d = 0.412\n",
      "Average increase = 20.5\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "t, p, df = ttest_ind(d_order.Quantity, nd_order.Quantity, alternative = 'larger')\n",
    "df1 = len(d_order.Quantity)-1\n",
    "df2 = len(nd_order.Quantity)-1\n",
    "s1 = d_order.Quantity.std()\n",
    "s2 = nd_order.Quantity.std()\n",
    "mu1 = d_order.Quantity.mean()\n",
    "mu2 = nd_order.Quantity.mean()\n",
    "s = np.sqrt((df1*s1**2+df2*s2**2)/(df1+df2))\n",
    "d = (mu1-mu2)/s\n",
    "print('p-value = {0:1.3e}'.format(p))\n",
    "print('t statistic = {0:1.3f}'.format(t))\n",
    "print(\"Cohen's d = {0:1.3f}\".format(d))\n",
    "print(\"Average increase = {0:1.1f}\".format(d*s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that discounts increase the volume of individual orders as a whole with a medium effect size, which in this case is an extra 20 items per order on average! It would be interesting to see if this is the case for orders where not every item is discounted. I'll look at that quickly below as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 1.438e-11\n",
      "t statistic = 6.778\n",
      "Cohen's d = 0.620\n",
      "Average increase = 30.7\n"
     ]
    }
   ],
   "source": [
    "x1 = d_order.Quantity.loc[d_order.MinDiscount == 0]\n",
    "t, p, df = ttest_ind(x1, nd_order.Quantity, alternative = 'larger')\n",
    "df1 = len(x1)-1\n",
    "df2 = len(nd_order.Quantity)-1\n",
    "s1 = x1.std()\n",
    "s2 = nd_order.Quantity.std()\n",
    "mu1 = x1.mean()\n",
    "mu2 = nd_order.Quantity.mean()\n",
    "s = np.sqrt((df1*s1**2+df2*s2**2)/(df1+df2))\n",
    "d = (mu1-mu2)/s\n",
    "print('p-value = {0:1.3e}'.format(p))\n",
    "print('t statistic = {0:1.3f}'.format(t))\n",
    "print(\"Cohen's d = {0:1.3f}\".format(d))\n",
    "print(\"Average increase = {0:1.1f}\".format(d*s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the having items without discount in the order don't make a difference. We can say with confidence that providing a discount increase the volume of an order as a whole, and increases the volume of a the discounted item as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6. Do discounts increase the gross profit of an order?\n",
    "### 6.1 Hypothesis Statement\n",
    "Knowing that more products are ordered when there is a discount applied, I wonder if the gross profit is increased. At first it makes sense that it should increase, but after taking the discount into consideration it becomes clear that the solution isn't known. The profit margin of every item is different, as is the discount of any given item. Since items are ordered in different quantities, it is impossible to know if a given discount has broken even, increased profits, or decreased profits. I will only consider the gross profit of an order. This analysis will be very similar to the analysis above, but it will require me to put together a more complex sql statement in order to access the necessary data. The hypotheses are the following:\n",
    "\n",
    "<center> H$_0$: $\\mu_{P|D}$ ≤ $\\mu_{P|ND}$ </center>\n",
    "<center>H$_a$: $\\mu_{P|D}$ > $\\mu_{P|ND}$</center>\n",
    "Where:<br>\n",
    "$\\mu_{P|ND}$ $\\equiv$ The average gross profit in a transaction given that there are no discounts.<br>\n",
    "$\\mu_{P|D}$ $\\equiv$ The average gross profit in a transaction given that there are discounts.<br><br>\n",
    "This is a one-tailed test, since I am only interested in determining if discounts increase the gross profit of an order. I could ask instead if there is a difference, but I'll cut straight to the chase for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Gathering Data\n",
    "A nested sql statement is used again. This time there are two levels of nesting. The deepest level calculates the gross profit per product, the second level performs some aggregate functions and grouping, and the final level returns the data from both levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_profit_statement = \"\"\"SELECT OrderId, \n",
    "                              Quantity, \n",
    "                              MaxDiscount, \n",
    "                              MinDiscount,\n",
    "                              GrossProfit\n",
    "                       FROM (\n",
    "                            SELECT OrderId,\n",
    "                                   SUM(Quantity) as Quantity,\n",
    "                                   MAX(Discount) AS MaxDiscount,\n",
    "                                   MIN(Discount) AS MinDiscount,\n",
    "                                   SUM(GrossProfit) AS GrossProfit\n",
    "                            FROM (\n",
    "                                 SELECT od.OrderId AS OrderId,\n",
    "                                        od.Quantity AS Quantity,\n",
    "                                        od.Discount AS Discount,\n",
    "                                        (p.UnitPrice-od.UnitPrice)*od.Quantity AS GrossProfit\n",
    "                                 FROM OrderDetail od\n",
    "                                 INNER JOIN Product p ON od.ProductId == p.Id\n",
    "                                 )\n",
    "                            GROUP BY OrderId\n",
    "                            )\n",
    "                       WHERE MaxDiscount > 0\n",
    "                       GROUP BY OrderId\"\"\"\n",
    "\n",
    "nd_profit_statement =\"\"\"SELECT OrderId, \n",
    "                              Quantity, \n",
    "                              MaxDiscount, \n",
    "                              MinDiscount,\n",
    "                              GrossProfit\n",
    "                       FROM (\n",
    "                            SELECT OrderId,\n",
    "                                   SUM(Quantity) as Quantity,\n",
    "                                   MAX(Discount) AS MaxDiscount,\n",
    "                                   MIN(Discount) AS MinDiscount,\n",
    "                                   SUM(GrossProfit) AS GrossProfit\n",
    "                            FROM (\n",
    "                                 SELECT od.OrderId AS OrderId,\n",
    "                                        od.Quantity AS Quantity,\n",
    "                                        od.Discount AS Discount,\n",
    "                                        (p.UnitPrice-od.UnitPrice)*od.Quantity AS GrossProfit\n",
    "                                 FROM OrderDetail od\n",
    "                                 INNER JOIN Product p ON od.ProductId == p.Id\n",
    "                                 )\n",
    "                            GROUP BY OrderId\n",
    "                            )\n",
    "                       WHERE MaxDiscount == 0\n",
    "                       GROUP BY OrderId\"\"\"\n",
    "statements = [d_profit_statement,nd_profit_statement]\n",
    "df = []\n",
    "for statement in statements:\n",
    "    raw = c.execute(statement)\n",
    "    data = raw.fetchall()\n",
    "    columns = raw.description\n",
    "    temp = pd.DataFrame(data)\n",
    "    temp.columns = [column[0] for column in columns]\n",
    "    df.append(temp)\n",
    "\n",
    "d_profit = df[0]\n",
    "nd_profit = df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "print(sum(d_profit.GrossProfit == 0))\n",
    "print(sum(nd_profit.GrossProfit == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is concerning that so many orders did not result in a profit. The interesting thing is that the orders without profit occur one right after another. Perhaps it's the case that the company simply doesn't put in the purchase price until the order is completed. Again, in the case of a real analysis I would investigate further, but since this is a fictitious company I will have to live with an assumption regardless of what I do. I'll evaluate the hypotheses next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Does gross profit increase in the presence of discounts?\n",
    "This analysis is almost identical to the analysis performed in section 5.4. I will use a two-sample one-tailed t-test in order to test the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 1.490e-04\n",
      "t statistic = 3.669\n",
      "Cohen's d = 0.466\n",
      "Average increase = 208.9\n"
     ]
    }
   ],
   "source": [
    "x1 = d_profit.GrossProfit.loc[d_profit.GrossProfit > 0]\n",
    "x2 = nd_profit.GrossProfit.loc[nd_profit.GrossProfit > 0]\n",
    "t, p, df = ttest_ind(x1, x2, alternative = 'larger')\n",
    "df1 = len(x1)-1\n",
    "df2 = len(x2)-1\n",
    "s1 = x1.std()\n",
    "s2 = x2.std()\n",
    "mu1 = x1.mean()\n",
    "mu2 = x2.mean()\n",
    "s = np.sqrt((df1*s1**2+df2*s2**2)/(df1+df2))\n",
    "d = (mu1-mu2)/s\n",
    "print('p-value = {0:1.3e}'.format(p))\n",
    "print('t statistic = {0:1.3f}'.format(t))\n",
    "print(\"Cohen's d = {0:1.3f}\".format(d))\n",
    "print(\"Average increase = {0:1.1f}\".format(d*s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a p-value of 2.382e-03 I can reject the null hypothesis and accept the alternative hypothesis that **discounts increase the gross profit of an order**. The effect size here is medium given Cohen's d-value, and the average increase is about $208.9 (assuming that price is measured in USD)! This does not take into account the orders that have no profit, since I'm assuming that those orders simply haven't been filled yet. \n",
    "It would be interesting to know if the amount of discount has an impact. I'll do that next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Does the *amount* of maximum discount impact the increase in gross profit?\n",
    "In order to check this I will perform an analysis of variance (ANOVA), which checks if the means of a parameter are equal in groups with different treatments. The null hypothesis is:\n",
    "<center>H$_0$: $\\mu_{P|D_1}$ = $\\mu_{P|D_2}$ = $\\mu_{P|D_3}$ ... = $\\mu_{P|D_i}$ </center>\n",
    "<center>Where</center>\n",
    "<center>$\\mu_{P|D_1,2,3...i}$ $\\equiv$ The profit given discount 1,2,3,...i</center>\n",
    "The alternative hypothesis is that at least one of the means is not equal to the other means, but there is no guarantee that it must be one and only one mean. This means that I must perform a deeper analysis if I reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MaxDiscount</th>\n",
       "      <td>1.197610e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.886875</td>\n",
       "      <td>0.051153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>3.420093e+07</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sum_sq     df         F    PR(>F)\n",
       "MaxDiscount  1.197610e+06    1.0  3.886875  0.051153\n",
       "Residual     3.420093e+07  111.0       NaN       NaN"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import module\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Fit model (ANOVA can be obtained from OLS)\n",
    "mod = ols('GrossProfit ~ MaxDiscount',\n",
    "                data=d_profit.loc[d_profit.GrossProfit > 0]).fit()\n",
    "                \n",
    "sm.stats.anova_lm(mod, typ=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cannot reject the null hypothesis since p = 0.051 > $\\alpha$. Thus, I cannot confidently say that the amount of maximum discount impacts the gross profit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "## 7. Do Fast Shipping Times Increase Sale Volume?\n",
    "### 7.1 Hypothesis Statement\n",
    "Fast shipping times are likely correlated with customer satisfaction. A satisfied customer is likely to order more than an unsatisfied customer, so it is reasonable to believe that shipping times impact customer behavior. I'll look to see if there is a difference in a) number of orders placed, and b) individual order product volume between individuals that receive their items quickly vs those that dont. The definition of \"fast\" will be determined once I look at the range of shipping times.\n",
    "The hypothesis for this data is similar to the hypotheses I have previously formed:\n",
    "<center> H$_0$: $\\mu_{P|FS}$ ≤ $\\mu_{P|SS}$ </center>\n",
    "<center>H$_a$: $\\mu_{P|FS}$ > $\\mu_{P|SS}$</center>\n",
    "Where:<br>\n",
    "$\\mu_{P|FS}$ $\\equiv$ The order volume given fast shipping.<br>\n",
    "$\\mu_{P|SS}$ $\\equiv$ The order volume given slow shipping.<br><br>\n",
    "This is again a one-tailed test, since I'm interested if fast shipping increases order volume. If it doesn't, then I'll check the inverse hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Gathering Data\n",
    "SQL is capable of dealing with datetime objects inline. SQLite3 has a function named JulianDay that allows mathematic manipulations to be performed on days to determine the difference in time between two datetime objects. I've called this function below to determine the lag time in shipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Carrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>809.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10662.500000</td>\n",
       "      <td>61.827711</td>\n",
       "      <td>8.491965</td>\n",
       "      <td>2.007229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>239.744656</td>\n",
       "      <td>50.748158</td>\n",
       "      <td>6.838682</td>\n",
       "      <td>0.779685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10248.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10455.250000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10662.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10869.750000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11077.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID    Quantity        Diff     Carrier\n",
       "count    830.000000  830.000000  809.000000  830.000000\n",
       "mean   10662.500000   61.827711    8.491965    2.007229\n",
       "std      239.744656   50.748158    6.838682    0.779685\n",
       "min    10248.000000    1.000000    1.000000    1.000000\n",
       "25%    10455.250000   26.000000    4.000000    1.000000\n",
       "50%    10662.500000   50.000000    7.000000    2.000000\n",
       "75%    10869.750000   81.000000    9.000000    3.000000\n",
       "max    11077.000000  346.000000   37.000000    3.000000"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_statement = \"\"\"\n",
    "               SELECT o.Id AS ID,\n",
    "               SUM(od.Quantity) AS Quantity,\n",
    "               (JULIANDAY(o.ShippedDate) - JULIANDAY(o.OrderDate)) AS Diff,\n",
    "               o.ShipVia as Carrier\n",
    "               FROM [Order] o\n",
    "               INNER JOIN OrderDetail od ON o.Id == od.OrderId\n",
    "               GROUP BY o.Id\n",
    "               \"\"\"\n",
    "raw = c.execute(st_statement)\n",
    "data = raw.fetchall()\n",
    "columns = raw.description\n",
    "st_order = pd.DataFrame(data)\n",
    "st_order.columns = [column[0] for column in columns]\n",
    "st_order.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are some rows without data. I will remove those rows since they cannot factor into the assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_order.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.491965389369591"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "st_order.Diff.plot.hist(bins = 20,figsize = (12,6));\n",
    "X_bar = st_order.Diff.mean()\n",
    "X_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Does fast shipping time increase the order volume?\n",
    "In order to use Bayes theorem, I must specify a prior distribution. The prior distribution is our belief as to how the system behaves. It is important to choose a prior that will not bias the results, since a poorly formed prior can greatly influence the outcome. Given that we do not have data on whether or not shipping times increase order volume for other companies, the prior that I specify cannot assume that there **is** a difference. In fact, I will specify a prior that assumes that there **is no difference** between the two datasets by using the mean and standard deviation of the joined set. I will use a poisson distribution as the prior with $\\lambda$ set to the maximum likelihood, $\\bar{X}$, since the data describes the likely time that it takes for a package to arrive.  This is exactly what Poisson was built for, and the histogram certainly looks like a poisson distribution.<br><br>\n",
    "Additionally, I'll choose my cutoff at four days. From the description of the data, 25% of all orders are filled in four days, which is half the time as the expected value and leaves me with more than enough data to model. Bayesian models usually require less data to have the same statistical power since prior information is known about the system and monte carlo methods can be used to leverage the little amount of data that is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pymc3 as pm\n",
    "\n",
    "# Define Data to use\n",
    "y = st_order.Diff\n",
    "y_fast = st_order.Diff.loc[st_order.Diff <=4]\n",
    "y_slow = st_order.Diff.loc[st_order.Diff > 4]\n",
    "# Define hyperparameters and distributions\n",
    "µ_lambda = y.mean()\n",
    "with pm.Model() as model:\n",
    "    fast_lambda = pm.Poisson('fast_lambda', µ_lambda)\n",
    "    slow_lambda = pm.Poisson('slow_lambda', µ_lambda)\n",
    "    nu = pm.Exponential('ν_minus_one', 1/29.) + 1 # This is for the student t, which I'll use\n",
    "    fast_group = pm.StudentT('fast', nu = nu, mu = )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymc3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-c2bd88b6fc24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpymc3\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define Data to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Quantity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymc3'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pymc3 as pm\n",
    "\n",
    "# Define Data to use\n",
    "y = st_order['Quantity','Diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
